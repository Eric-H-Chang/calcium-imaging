{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9697bc59",
   "metadata": {},
   "source": [
    "# TH_V4 Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3103389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must run this cell prior to any other cells\n",
    "# This pipeline exports excel files of traces that pass a simple selectivity filter, and quantifications of various components of each response\n",
    "\n",
    "def extract_info(file):\n",
    "#get the information out of the pickle file\n",
    "#input is: the file name of the pkl\n",
    "#output is:\n",
    "    #C which is the traces for each ROI, \n",
    "    #coordinates which ahs coordiantes for each ROI, \n",
    "    #and com which is center of mass of each ROI\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "    data = pickle.load(open(file,'rb'))\n",
    "    C = data['C_array']\n",
    "    S = data['S_array']\n",
    "    coords = data['coords']\n",
    "    coordinates = []\n",
    "    com = []\n",
    "    try:\n",
    "        for i in range(np.shape(C)[0]):\n",
    "            coordinates.append(coords[i]['coordinates'][1:-2])\n",
    "            com.append(coords[i]['CoM'])\n",
    "    except:\n",
    "        print('coords messed up')\n",
    "    return C, coordinates, com\n",
    "\n",
    "\n",
    "def find_artifacts(data):\n",
    "#function to find the frames of possible artifacts in the data\n",
    "#input is data_xxx which is the traces for each ROI\n",
    "    #data input has shape (cells, frames)\n",
    "#Output is a list of which frames have artifacts\n",
    "    import scipy.signal as sig\n",
    "    import numpy as np\n",
    "    n_cells = np.shape(data)[0]\n",
    "    peaks = []\n",
    "    for i in range(n_cells):\n",
    "        peaks.append(sig.find_peaks(data[i],height=0.02,prominence=0.02,width=5)[0])\n",
    "\n",
    "    matrix = []\n",
    "    win_size = 20\n",
    "    wins = np.arange(win_size/2,np.shape(data)[1],win_size)\n",
    "\n",
    "    for i in wins:\n",
    "        n_peaks = 0\n",
    "        #find how many cells have peaks in each ten frame window\n",
    "        for j in range(np.shape(peaks)[0]):\n",
    "            if any(x >= i-10 and x < i+10 for x in peaks[j]):\n",
    "                n_peaks = n_peaks+1\n",
    "        matrix.append(n_peaks)\n",
    "\n",
    "    mat = np.array(matrix)\n",
    "    artifacts = wins[np.where(mat>np.round(n_cells*0.25))[0]]\n",
    "    return artifacts\n",
    "\n",
    "def find_edges(data,max_x,base):\n",
    "#find edges\n",
    "#Input is data_xxx which is all the traces, and max_x which is the frame where the max peak is in find_responders\n",
    "#Output is left and right edges of the response\n",
    "    #base = np.mean(data[0:(int(np.round(len(data)*0.5)))]) #baseline is average of lower half of data points\n",
    "    '''\n",
    "    if np.min(data)>0.005:\n",
    "        base = np.mean(data[:200])\n",
    "    else: \n",
    "        base = 0.005\n",
    "    '''\n",
    "    start = max_x\n",
    "    i = data[start]\n",
    "    l_frames=0\n",
    "    r_frames=0\n",
    "    while (i>base) & (start>1):\n",
    "        start=start-1\n",
    "        i=data[start]\n",
    "        l_frames=l_frames+1\n",
    "\n",
    "    start = max_x \n",
    "    i =data[start]\n",
    "    while (i>base) & (start<len(data)-1):\n",
    "        start=start+1\n",
    "        i=data[start]\n",
    "        r_frames=r_frames+1\n",
    "    l = max_x-l_frames\n",
    "    r = max_x+r_frames\n",
    "    return l, r\n",
    "\n",
    "def find_responders(data, coords, dose, **kwargs):\n",
    "#find which cells are responders and the features of the response\n",
    "# Input is:\n",
    "    #data_xx which is the traces for every ROI\n",
    "    #coords which is the coordinates for every ROI\n",
    "    #dose which is the frame window of the stimlus [xxxx,xxxx]\n",
    "    #control which is the frame window of the saline [xxxx,xxxx]\n",
    "    #params is the parameters for find peaks which is height, prominence, and width\n",
    "# Output is a dictionary with a bunch of variables:\n",
    "    #time which converts frames to seconds\n",
    "    #responders which is all the cells that responded during dose window\n",
    "    #noisy saline which are all the responders that also had noisy saline windows and were excluded\n",
    "    #slope is height/rise time for response\n",
    "    #rise time is from beginning of response to peak\n",
    "    #decay time is from peak to end of response\n",
    "    #width is length of response\n",
    "    #height is amplitude of peak\n",
    "    #num peaks is number of peaks above threshold during stimulus window\n",
    "    #x_roi is all of the x coordinates for each ROI (easier for making scatter plots)\n",
    "    #y_roi is all of the y coordinates for each ROI\n",
    "    #integral_resp is the integral of the response\n",
    "    #integral_dose is the integral of the whole dose window\n",
    "    #integral_saline is the integral of the whole saline window\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import scipy.signal as sig\n",
    "    from scipy import integrate\n",
    "    #convert frames to time\n",
    "    fr = 20\n",
    "    time = np.arange(0,6000,1)/fr\n",
    "    \n",
    "    #initialize lists to add variables\n",
    "    responders = []\n",
    "    noisy_saline = []\n",
    "    rise_time_max = []; decay_time_max = []; width_max = []; height_max = []; integral_max = []; slope_max = []\n",
    "    rise_time_all = []; decay_time_all = []; width_all = []; integral_all = []; slope_all = []\n",
    "    rise_time_avg = []; decay_time_avg = []; width_avg = []; integral_avg = []; slope_avg = []\n",
    "    integral_dose = []; integral_saline = []; dose_trace = []; dose_sum = []; num_peaks = []; peak_info = []; \n",
    "    peak_time = []; peak_heights = []; avg_peak_heights = []; peak_traces = []; x_roi = []; y_roi = []\n",
    "    #h=params['h']; p =params['p']; w =params['w'];\n",
    "    \n",
    "    #specify frames to look at for control and stimulus window\n",
    "    control_data = data[:,0:dose]\n",
    "    dose_data = data[:,dose:dose+2000]\n",
    "    trace_data = data[:,0:dose+2000]\n",
    "    #loop through each ROI\n",
    "    for i in range(np.shape(data)[0]): \n",
    "        #set peak height based on baseline\n",
    "        sort_data = np.sort(data[i])\n",
    "        baseline = np.mean(sort_data[0:(int(np.round(len(sort_data)*0.8)))]) #baseline is average of lower half of data points\n",
    "        variation = np.std(sort_data[0:(int(np.round(len(sort_data)*0.8)))])\n",
    "        w = 10\n",
    "        p=baseline+3*variation\n",
    "        h=baseline+3*variation\n",
    "        rise_time_cell = []; decay_time_cell = []; width_cell = []; height_cell = []; integral_cell = []; slope_cell = []\n",
    "        coord_list = coords[i]\n",
    "        x = []\n",
    "        y= []\n",
    "        #make 2 sepearte lists for x and y coordinates for each ROI\n",
    "        for j in range(0,len(coord_list)):\n",
    "            x.append(coord_list[j,0])\n",
    "            y.append(coord_list[j,1])\n",
    "        x_roi.append(x)\n",
    "        y_roi.append(y)\n",
    "        \n",
    "        #get rid of cells with no activity\n",
    "        if abs(np.max(data))-abs(np.min(data))>.009:\n",
    "        \n",
    "            #Look for peaks in dose interval\n",
    "            if sig.find_peaks(dose_data[i],height=h,prominence = p,width = w)[0].shape[0]>0: \n",
    "\n",
    "                #find max  peak amplitude in stimulus window\n",
    "                peaks = sig.find_peaks(dose_data[i],height=h,prominence=p,width=w)\n",
    "                max_peak = np.max(peaks[1]['peak_heights'])\n",
    "\n",
    "                #look if there are saline peaks 50% height of stimulus peaks\n",
    "                saline_peaks, _ = sig.find_peaks(control_data[i],height =0.5*max_peak,width=w) #saline\n",
    "\n",
    "                if len(saline_peaks)>0: #Exclude for cells with noisy saline periods\n",
    "                    noisy_saline.append(i)\n",
    "\n",
    "                else: #responders without peaks in saline\n",
    "                    responders.append(i)\n",
    "                    num_peaks.append(len(peaks[0]))\n",
    "                    peak_time.append(peaks[0][0])\n",
    "                    peak_heights.append(peaks[1]['peak_heights']*100)\n",
    "                    avg_peak_heights.append(np.mean(peaks[1]['peak_heights']*100))\n",
    "                    \n",
    "                    #find integral of whole control and stimulus window\n",
    "                    integral_dose.append(integrate.simps(dose_data[i]))\n",
    "                    integral_saline.append(integrate.simps(control_data[i]))\n",
    "                    #find sum\n",
    "                    dose_sum.append(sum(dose_data[i]))\n",
    "                    #find features of each peak\n",
    "                    for ii in range(0,len(peaks[0])):\n",
    "                        x_peak = peaks[0][ii]\n",
    "                        l_peak, r_peak = find_edges(dose_data[i],x_peak,baseline)\n",
    "                        peak_traces.append(dose_data[i][l_peak:r_peak])\n",
    "                        rise_time_cell.append(x_peak-l_peak)\n",
    "                        decay_time_cell.append(r_peak-x_peak)\n",
    "                        width_cell.append(r_peak-l_peak)\n",
    "                        integral_cell.append(integrate.simps(dose_data[i,l_peak:r_peak]))\n",
    "                        slope_cell.append(((peaks[1]['peak_heights'][ii])*100)/(x_peak-l_peak))\n",
    "                   \n",
    "                    rise_time_all.append(rise_time_cell); decay_time_all.append(decay_time_cell) \n",
    "                    width_all.append(width_cell); integral_all.append(integral_cell); slope_all.append(slope_cell)\n",
    "                    rise_time_avg.append(np.mean(rise_time_cell)); decay_time_avg.append(np.mean(decay_time_cell)) \n",
    "                    width_avg.append(np.mean(width_cell)); integral_avg.append(np.mean(integral_cell)) \n",
    "                    slope_avg.append(np.mean(slope_cell));\n",
    "\n",
    "                    #find features of max peak\n",
    "                    max_x =  peaks[0][np.where(peaks[1]['peak_heights']==np.max(peaks[1]['peak_heights']))][0] #find x value of biggest peak\n",
    "\n",
    "                    #find edges\n",
    "                    l, r = find_edges(dose_data[i],max_x,baseline)\n",
    "                    \n",
    "                    #Calculate features of biggest response in stimulus window\n",
    "                    rise_time_max.append(max_x-l)\n",
    "                    decay_time_max.append(r-max_x)\n",
    "                    width_max.append(r-l)\n",
    "                    height_max.append(np.max(peaks[1]['peak_heights'])*100)\n",
    "                    integral_max.append(integrate.simps(dose_data[i,l:r]))\n",
    "                    slope_max.append((np.max(peaks[1]['peak_heights'])*100)/(max_x-l))\n",
    "                    peak_info.append(peaks)\n",
    "                    dose_trace.append(trace_data[i])\n",
    "    \n",
    "    #flip dose trace to be in excel\n",
    "    dose_trace = np.transpose(dose_trace)\n",
    "    file=kwargs.get('f')\n",
    "    if file == None:\n",
    "        print('artifacts, dont save')\n",
    "    else:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)   \n",
    "        pd.DataFrame(dose_trace).to_excel(file)\n",
    "    \n",
    "    info = {'time':time,'responders':responders, \"noisy_saline\":noisy_saline, \"slope_max\":slope_max, \n",
    "            \"rise_time_max\":rise_time_max, \"decay_time_max\":decay_time_max, \"width_max\":width_max, \"height_max\":height_max, \n",
    "            \"slope_all\":slope_all, \"rise_time_all\":rise_time_all, \"decay_time_all\":decay_time_all, \"width_all\":width_all, \n",
    "            \"integral_all\":integral_all, \"slope_avg\":slope_avg, \"rise_time_avg\":rise_time_avg, \n",
    "            \"decay_time_avg\":decay_time_avg, \"width_avg\":width_avg, \"integral_avg\":integral_avg,'peak_time':peak_time,\n",
    "            \"peak_heights\":peak_heights, \"avg_peak_heights\":avg_peak_heights, \"peak_traces\":peak_traces,\n",
    "            \"num_peaks\":num_peaks,\"x_roi\":x_roi,\"y_roi\":y_roi, \"integral_max\":integral_max, \"integral_dose\":integral_dose,\n",
    "            \"integral_saline\":integral_saline,\"dose_sum\":dose_sum,\"peak_info\":peak_info, \"dose_trace\":dose_trace}\n",
    "\n",
    "    return info\n",
    "\n",
    "def analyze_baseline(data, coords, **kwargs):\n",
    "#find which cells are responders and the features of the response\n",
    "# Input is:\n",
    "    #data_xx which is the traces for every ROI\n",
    "    #coords which is the coordinates for every ROI\n",
    "    #dose which is the frame window of the stimlus [xxxx,xxxx]\n",
    "    #control which is the frame window of the saline [xxxx,xxxx]\n",
    "    #params is the parameters for find peaks which is height, prominence, and width\n",
    "# Output is a dictionary with a bunch of variables:\n",
    "    #time which converts frames to seconds\n",
    "    #responders which is all the cells that responded during dose window\n",
    "    #noisy saline which are all the responders that also had noisy saline windows and were excluded\n",
    "    #slope is height/rise time for response\n",
    "    #rise time is from beginning of response to peak\n",
    "    #decay time is from peak to end of response\n",
    "    #width is length of response\n",
    "    #height is amplitude of peak\n",
    "    #num peaks is number of peaks above threshold during stimulus window\n",
    "    #x_roi is all of the x coordinates for each ROI (easier for making scatter plots)\n",
    "    #y_roi is all of the y coordinates for each ROI\n",
    "    #integral_resp is the integral of the response\n",
    "    #integral_dose is the integral of the whole dose window\n",
    "    #integral_saline is the integral of the whole saline window\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import scipy.signal as sig\n",
    "    from scipy import integrate\n",
    "    #convert frames to time\n",
    "    fr = 20\n",
    "    time = np.arange(0,1000,1)/fr\n",
    "    #initialize lists to add variables\n",
    "    rise_time_max = []; decay_time_max = []; width_max = []; height_max = []; integral_max = []; slope_max = []\n",
    "    rise_time_all = []; decay_time_all = []; width_all = []; integral_all = []; slope_all = []\n",
    "    rise_time_avg = []; decay_time_avg = []; width_avg = []; integral_avg = []; slope_avg = []\n",
    "    integral_trace = []; data_trace = []; trace_sum = []; num_peaks = []; peak_info = []; peak_time = [] \n",
    "    peak_heights = []; avg_peak_heights = []; peak_traces = []; active_cells = []; baseline_list = []; variation_list = []\n",
    "    x_roi = []\n",
    "    y_roi = []\n",
    "    #h=params['h']; p =params['p']; w =params['w'];\n",
    "    \n",
    "\n",
    "    #loop through each ROI\n",
    "    for i in range(np.shape(data)[0]): \n",
    "        \n",
    "        #set peak height based on baseline\n",
    "        sort_data = np.sort(data[i][data[i]>0])\n",
    "        baseline = np.mean(sort_data[0:(int(np.round(len(sort_data)*0.5)))]) #baseline is average of lower half of data points\n",
    "        variation = np.std(sort_data[0:(int(np.round(len(sort_data)*0.5)))])\n",
    "        baseline_list.append(baseline)\n",
    "        variation_list.append(variation)\n",
    "        w = 3\n",
    "        p=baseline+2*variation\n",
    "        h=baseline+2*variation\n",
    "        rise_time_cell = []; decay_time_cell = []; width_cell = []; height_cell = []; integral_cell = []; slope_cell = []\n",
    "        coord_list = coords[i]\n",
    "        x = []\n",
    "        y= []\n",
    "        #make 2 sepearte lists for x and y coordinates for each ROI\n",
    "        for j in range(0,len(coord_list)):\n",
    "            x.append(coord_list[j,0])\n",
    "            y.append(coord_list[j,1])\n",
    "        x_roi.append(x)\n",
    "        y_roi.append(y)\n",
    "\n",
    "        if abs(np.max(data))-abs(np.min(data))>.009:\n",
    "            if sig.find_peaks(data[i],height=h,prominence = p,width = w)[0].shape[0]>0: \n",
    "                active_cells.append(i)\n",
    "                #find max  peak amplitude in stimulus window\n",
    "                peaks = sig.find_peaks(data[i],height=h,prominence=p,width=w)\n",
    "\n",
    "                max_peak = np.max(peaks[1]['peak_heights'])\n",
    "\n",
    "                num_peaks.append(len(peaks[0]))\n",
    "                peak_time.append(peaks[0][0])\n",
    "                peak_heights.append(peaks[1]['peak_heights']*100)\n",
    "                avg_peak_heights.append(np.mean(peaks[1]['peak_heights']*100))\n",
    "\n",
    "                #find integral of whole control and stimulus window\n",
    "                integral_trace.append(integrate.simps(data[i]))\n",
    "                #find sum\n",
    "                trace_sum.append(sum(data[i]))\n",
    "                #find features of each peak\n",
    "                for ii in range(0,len(peaks[0])):\n",
    "                    x_peak = peaks[0][ii]\n",
    "                    l_peak, r_peak = find_edges(data[i],x_peak,baseline)\n",
    "                    peak_traces.append(data[i][l_peak:r_peak])\n",
    "                    rise_time_cell.append(x_peak-l_peak)\n",
    "                    decay_time_cell.append(r_peak-x_peak)\n",
    "                    width_cell.append(r_peak-l_peak)\n",
    "                    integral_cell.append(integrate.simps(data[i,l_peak:r_peak]))\n",
    "                    slope_cell.append(((peaks[1]['peak_heights'][ii])*100)/(x_peak-l_peak))\n",
    "\n",
    "                rise_time_all.append(rise_time_cell); decay_time_all.append(decay_time_cell); width_all.append(width_cell)\n",
    "                integral_all.append(integral_cell); slope_all.append(slope_cell) \n",
    "                rise_time_avg.append(np.mean(rise_time_cell)); decay_time_avg.append(np.mean(decay_time_cell))\n",
    "                width_avg.append(np.mean(width_cell)); integral_avg.append(np.mean(integral_cell))\n",
    "                slope_avg.append(np.mean(slope_cell))\n",
    "\n",
    "                #find features of max peak\n",
    "                max_x =  peaks[0][np.where(peaks[1]['peak_heights']==np.max(peaks[1]['peak_heights']))][0] #find x value of biggest peak\n",
    "\n",
    "                #find edges\n",
    "                l, r = find_edges(data[i],max_x,baseline)\n",
    "\n",
    "                #Calculate features of biggest response in stimulus window\n",
    "                rise_time_max.append(max_x-l)\n",
    "                decay_time_max.append(r-max_x)\n",
    "                width_max.append(r-l)\n",
    "                height_max.append(np.max(peaks[1]['peak_heights'])*100)\n",
    "                integral_max.append(integrate.simps(data[i,l:r]))\n",
    "                slope_max.append((np.max(peaks[1]['peak_heights'])*100)/(max_x-l))\n",
    "                peak_info.append(peaks)\n",
    "                data_trace.append(data[i])\n",
    "\n",
    "    #flip dose trace to be in excel\n",
    "    data_trace = np.transpose(data_trace)\n",
    "    file=kwargs.get('f')\n",
    "    if file == None:\n",
    "        print('artifacts, dont save')\n",
    "    else:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)   \n",
    "        pd.DataFrame(data_trace).to_excel(file)\n",
    "    \n",
    "    info = {'time':time, \"active_cells\":active_cells,\"slope_max\":slope_max, \"rise_time_max\":rise_time_max, \n",
    "            \"decay_time_max\":decay_time_max, \"width_max\":width_max, \"height_max\":height_max, \"slope_all\":slope_all, \n",
    "            \"rise_time_all\":rise_time_all, \"decay_time_all\":decay_time_all, \"width_all\":width_all, \n",
    "            \"integral_all\":integral_all, \"slope_avg\":slope_avg, \"rise_time_avg\":rise_time_avg, \n",
    "            \"decay_time_avg\":decay_time_avg, \"width_avg\":width_avg, \"integral_avg\":integral_avg, \"peak_time\":peak_time, \n",
    "            \"peak_heights\":peak_heights, \"avg_peak_heights\":avg_peak_heights, \"peak_traces\":peak_traces,\n",
    "            \"baseline_list\":baseline_list,\"variation_list\":variation_list, \"num_peaks\":num_peaks,\"x_roi\":x_roi,\n",
    "            \"y_roi\":y_roi, \"integral_max\":integral_max, \"integral_trace\":integral_trace,\"trace_sum\":trace_sum,\n",
    "            \"peak_info\":peak_info, \"data_trace\":data_trace}\n",
    "\n",
    "    return info\n",
    "\n",
    "def save_data(*args):\n",
    "    #saves features in a csv\n",
    "    #last arg has to be the filename\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    data = args[0:len(args)-1]\n",
    "    pd.DataFrame(data).to_csv(args[-1])\n",
    "    return\n",
    "    \n",
    "def plot_traces(dose, responders, data, title):\n",
    "    import math\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    num_resp = math.ceil(len(responders)/20)\n",
    "    start=0\n",
    "    for i in range(num_resp):\n",
    "        fig, axs = plt.subplots(20)\n",
    "        plt.subplots_adjust(wspace=0.1,hspace=0.1)\n",
    "        fig.set_size_inches(8, 8)\n",
    "        fig.suptitle(title,fontsize=16,y=0.92)\n",
    "        [axi.set_axis_off() for axi in axs.ravel()]\n",
    "        for j in range(0,20):\n",
    "            try:\n",
    "                axs[j].plot(data[responders[j+start],(dose-1000):(dose+2000)])\n",
    "            except:\n",
    "                print('')\n",
    "        start=start+20\n",
    "\n",
    "def plot_alltraces_1responder(dose, cells, responders, data, stimulus, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "    num_neur = math.ceil(len(responders)/20)\n",
    "    start=0\n",
    "    fig, axs = plt.subplots(len(cells))\n",
    "    fig.set_size_inches(12, 15)\n",
    "    fig.suptitle(title, fontsize=18,y=0.92)\n",
    "    [axi.set_axis_off() for axi in axs.ravel()]\n",
    "    max_amp = []\n",
    "    for i in range(len(cells)):\n",
    "        max_amp.append(np.max(data[cells[i],(dose-1000):(dose+2000)]))\n",
    "    max_y = np.max(max_amp)\n",
    "    \n",
    "    for i in range(len(cells)):\n",
    "        if i in responders:\n",
    "            axs[i].set_ylim([0,max_y])\n",
    "            axs[i].vlines(stimulus,0,max_y,'k')\n",
    "            axs[i].plot(data[cells[i],(dose-1000):(dose+2000)],'r')\n",
    "            \n",
    "        else:\n",
    "            axs[i].set_ylim([0,max_y])\n",
    "            axs[i].vlines(stimulus,0,max_y,'k')\n",
    "            axs[i].plot(data[cells[i],(dose-1000):(dose+2000)],'b')   \n",
    "            \n",
    "def plot_responders(dose, cells, responders, data, stimulus, info):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "    num_neur = math.ceil(len(responders)/20)\n",
    "    start=0\n",
    "    fig, axs = plt.subplots(len(responders))\n",
    "    fig.set_size_inches(12, 20)\n",
    "    [axi.set_axis_off() for axi in axs.ravel()]\n",
    "    max_amp = []\n",
    "    for r in responders:\n",
    "        if dose>=1000:\n",
    "            max_amp.append(np.max(data[cells[r],(dose-1000):(dose+2000)]))\n",
    "        else:\n",
    "            max_amp.append(np.max(data[cells[r],(0):(dose+2000)]))\n",
    "    max_y = np.max(max_amp)\n",
    "    r = 0\n",
    "    for i in range(len(cells)):\n",
    "        if i in responders:\n",
    "            axs[r].set_ylim([0,max_y])\n",
    "            axs[r].vlines(stimulus,0,max_y,'k')\n",
    "            axs[r].plot(data[cells[i],(0):(dose+2000)])\n",
    "            axs[r].scatter(info['peak_info'][r][0]+stimulus,info['peak_info'][r][1]['peak_heights'],color='red',marker='x')\n",
    "            r = r+1\n",
    "            \n",
    "def plot_alltraces_2responders(dose, cells, responders1, responders2, data, stimulus1,stimulus2, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, axs = plt.subplots(len(cells))\n",
    "    fig.set_size_inches(16, 20)\n",
    "    #fig.suptitle(title, fontsize=18,y=0.92)\n",
    "    [axi.set_axis_off() for axi in axs.ravel()]\n",
    "    max_amp = []\n",
    "    for i in range(len(cells)):\n",
    "        max_amp.append(np.max(data[cells[i],dose[0]:dose[1]]))\n",
    "    max_y = np.max(max_amp)\n",
    "    \n",
    "    for i in range(len(cells)):\n",
    "        if (i in responders1) & (i in responders2):\n",
    "            axs[i].set_ylim([0,max_y])\n",
    "            axs[i].plot(data[cells[i],(dose-1000):(dose+2000)],'m')\n",
    "            axs[i].vlines(stimulus1,0,max_y,'k')\n",
    "            axs[i].vlines(stimulus2,0,max_y,'k')\n",
    "        elif (i in responders1):\n",
    "            axs[i].set_ylim([0,max_y])\n",
    "            axs[i].plot(data[cells[i],dose[0]:dose[1]],'r')\n",
    "            axs[i].vlines(stimulus1,0,max_y,'k')\n",
    "            axs[i].vlines(stimulus2,0,max_y,'k')\n",
    "        elif (i in responders2):\n",
    "            axs[i].set_ylim([0,max_y])\n",
    "            axs[i].plot(data[cells[i],dose[0]:dose[1]],'b')\n",
    "            axs[i].vlines(stimulus1,0,max_y,'k')\n",
    "            axs[i].vlines(stimulus2,0,max_y,'k')\n",
    "        else:\n",
    "            axs[i].set_ylim([0,max_y])\n",
    "            axs[i].plot(data[cells[i],dose[0]:dose[1]],'k')\n",
    "            axs[i].vlines(stimulus1,0,max_y,'k')\n",
    "            axs[i].vlines(stimulus2,0,max_y,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ced2e6",
   "metadata": {},
   "source": [
    "# Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bc22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define directory and pkl file\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import os\n",
    "\n",
    "dir = 'C:\\\\ENTER_DIRECTORY_HERE'\n",
    "\n",
    "file = 'C:\\\\FILE_DIRECTORY\\\\FILENAME.pkl'\n",
    "data_FILENAME, coords, com = extract_info(file)\n",
    "\n",
    "# Generate data foler \"output...\" and export traces that pass filter \n",
    "\n",
    "dose = 1000 # Dose is when a solution was applied to nerve, must be > 0\n",
    "output_FILENAME = find_responders(data_FILENAME,coords,dose, f = os.path.join(dir,'FILENAME.xlsx'))\n",
    "pickle.dump( output_FILENAME, open( 'FILENAME.pkl', \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b123b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline Analysis, export accepted traces from CaImAn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "file = 'C:\\\\FILE_DIRECTORY\\\\FILENAME.pkl'\n",
    "data_FILENAME, coords_FILENAME, com_FILENAME = extract_info(file)\n",
    "resp_FILENAME = analyze_baseline(data_FILENAME,coords_FILENAME,f = os.path.join(dir,'baseline_FILENAME.xlsx'))\n",
    "print('FILENAME')\n",
    "print('Number of active neurons: '+ str(np.shape(coords_FILENAME)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load component data\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "files = os.listdir(dir)\n",
    "\n",
    "# Can replace cap with whatever solution was put on nerve\n",
    "\n",
    "cap_heights = []\n",
    "cap_widths = []\n",
    "cap_npeaks = []\n",
    "cap_tpeaks = []\n",
    "cap_integrals = []\n",
    "\n",
    "data = output_FILENMAE\n",
    "cap_heights = data['avg_peak_heights']\n",
    "cap_widths = data['width_avg']\n",
    "cap_npeaks = data['num_peaks']\n",
    "cap_tpeaks = data['peak_time']\n",
    "cap_integrals = data['integral_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be43e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export trace components\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "heights = os.path.join(dir,'FILENAME_heights.xlsx')\n",
    "cap_heights = {'AvgHeightsPerCell':cap_heights}\n",
    "cap_heights = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in cap_heights.items() ]))\n",
    "cap_heights.to_excel(heights)\n",
    "\n",
    "widths = os.path.join(dir,'FILENAME_width.xlsx')\n",
    "cap_widths = {'AvgWidthsPerCell':cap_widths}\n",
    "cap_widths = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in cap_widths.items() ]))\n",
    "cap_widths.to_excel(widths)\n",
    "\n",
    "npeaks = os.path.join(dir,'FILENAME_npeaks.xlsx')\n",
    "cap_npeaks = {'NpeaksPerCell':cap_npeaks}\n",
    "cap_npeaks = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in cap_npeaks.items() ]))\n",
    "cap_npeaks.to_excel(npeaks)\n",
    "\n",
    "tpeaks = os.path.join(dir,'FILENAME_tpeaks.xlsx')\n",
    "cap_tpeaks = {'TpeaksPerCell':cap_tpeaks}\n",
    "cap_tpeaks = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in cap_tpeaks.items() ]))\n",
    "cap_tpeaks.to_excel(tpeaks)\n",
    "\n",
    "integral = os.path.join(dir,'FILENAME_integral.xlsx')\n",
    "cap_integrals = {'integralsPerCell':cap_integrals}\n",
    "cap_integrals = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in cap_integrals.items() ]))\n",
    "cap_integrals.to_excel(integral)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
